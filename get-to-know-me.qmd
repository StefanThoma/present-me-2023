---
title: "Get To Know"
author: "Stefan Thoma"
format: revealjs
bibliography: references.bib
---

# Personal

```{r}
mapdf <- tibble::tibble(town = c("University Bern", "ETH Zürich", "Gelterkinden", "Roche"),
                        lng = c(7.4381, 8.5476, 7.85658, 7.6025032),
                        lat = c(46.9505, 47.3764, 47.46471, 47.559459))

library(leaflet)
leaflet() %>%
    addProviderTiles(providers$OpenStreetMap.CH) %>%
  #?addTiles(urlTemplate = ) %>%  # Add default OpenStreetMap map tiles
  addMarkers(lng=mapdf$lng, lat=mapdf$lat, label = mapdf$town)
```

## Family {auto-animate="true"}

![](images/Stefan&Leo.JPG)

## Free Time

-   Woodworking & Woodturning

    -   Volunteering at Workshop

-   Painting

-   Photography

-   Coffee

# Professional

## Education

-   MSc Cognitive Psychology & Methods in Bern
    -   Increasing awareness of climate change with immersive virtual reality @thoma2023.
    -   Accepted January 2023 in Frontiers in Psychology \| Frontiers in Virtual Reality
-   MSc Statistics at ETHZ (December 2021)
    -   Estimating Relevance in Replication Studies

## Previous (relevant) Work

::: columns
::: {.column width="50%"}
-   Teaching
    -   Statistics, R, and reproducible research
    -   to students and faculty
    -   since \~ 2017
-   Creating teaching materials
-   Statistical and R consulting
:::

::: {.column width="50%"}
::: panel-tabset
### Statistik IV

<iframe src="https://methodenlehre.github.io/Statistik-IV-quarto/" title="*Statistik IV* lecture material" width="960" height="500">

</iframe>

### R & Stats

<iframe src="https://methodenlehre.github.io/intro-to-rstats-hs21/" title="*Intro to R* lecture material" width="960" height="500">

</iframe>
:::
:::
:::

## At Roche

::: columns
::: {.column width="50%"}
<!--     -   Ease the switch from SAS to R -->

-   Since November 2022

-   Introduction to Teal Materials

-   Part of the Admiral Hackathon

    -   Introduction to R (\>500 Participants)

    -   Registration & Submission App
:::

::: {.column width="50%"}
::: panel-tabset
### App

<iframe src="https://zxqguo-stefan0pascal-thoma.shinyapps.io/data_upload/" title="Admiral Hackathon App" width="960" height="500">

</iframe>

### SAS to R

<iframe src="https://pharmaverse.github.io/intro-to-r-for-sas-programmers-workshop/" title="Introduction to R for SAS programmers" width="960" height="500">

</iframe>

### `teal`

<iframe src="https://stefanthoma.github.io/teal_intro/" title="Introduction to teal" width="960" height="500">

</iframe>
:::
:::
:::

## Why ADS?

-   Work with Substance <!-- Being part of the drug development process is very meaningful to me personally. -->
-   Work as part of a team towards a shared goal <!-- Not how it is in academia -->
-   Switch to R
    -   Low barrier of entry
    -   Focus on code re-usability
    -   Co create workflows and environments
    -   Contribute to the shift in this industry
    -   
-   Personal growth

::: notes
Broadly speaking there are three points:

-   It is work That I enjoy
-   Work that I am qualified for
-   Work that allows me to grow my skills
:::

# Project

## Estimating Relevance within Replication Studies

-   Masters Thesis in Statistics

-   Apply the concept of Relevance to large scale replication studies.

::: aside
Supervised by Prof. em. Dr. Werner Stahel and Prof. Dr. Martin Mächler
:::

::: notes
I chose to focus on the intersection area between statistics and psychology for my masters thesis in statistics.

My thesis was supervised by Werner Stahel and Martin Mächler. And the goal was to apply the novel concept of the relevance parameter to three large scale replication studies. Today, I will be focusing on one particular replication study -- for the sake of brevity.

In particular, I want to talk about how I implemented this analysis and what I would do differently now.
:::

## Measure of Relevance

-   Alternative to p-values by @stahel2021

    -   Testing against Null vs testing Relevance

-   $Rle = \frac{\hat{\theta}}{\zeta}$

![Relevance Categories](images/categories.png)

::: notes
Let's talk about this Relevance parameter. So, the parameter was designed by Werner Stahel to be an alternative to p-values. You simply take the parameter of interest, in this case the standardised mean difference between the two groups, and you divide it by the minimally relevant effect size. Relevance ranges now between - infinite and + infinite. With a directed hypothesis a Relevance larger than 1 represents a relevant effect.

While p-values mostly represent estimation certainty / accuracy, the relevance parameter also encodes information of effect magnitude. The formula in the slide is for the estimated relevance Rle. We can then create a confidence interval around our estimate, with which we can express certainty of our estimation.

This leads us to the different relevance categorizations: Best case scenario: the CI is to the right of our relevance threshold. Worst case: the upper bound of our CI is negative.

Mention: units of relevance are in units of minimally relevant effectsize strongly related to equivalence testing problem if expected effect is very close to the minimally relevant effect.

For this study $\zeta$ was .1
:::

## Measure of Relevance

-   $\zeta$ must be decided on
-   Defaults are useful:
    -   For our study: $\zeta = 0.1$
    -   $\hat{\theta} = 0.2$ -\> $Rle = 2$

::: notes
note here that the choice of zeta has a large impact on the results. Zeta must be chosen by researcher, but some default values can be suggested.
:::

<!-- ## Reproducibility Crisis in Psychology -->

<!-- ![Estimated replication scores by @youyou2023](images/replication_score.jpg) -->

<!-- ::: notes -->

<!-- So, it is estimated that less than half of psychology studies of the past 20 years are reproducible. -->

<!-- This means that many of the psychological phenomena we learned about are not real or at least much less impactful than the literature might suggest.  -->

<!-- This may be due to many factors, such as publication bias, poor research practices, or from a misunderstanding on p-values.  -->

<!-- :::  -->

## Priming study by @albarracin2008

-   Activity `priming` should lead to better `score` than inactivity priming

-   Replication by @ebersole2018:

    -   N = 884
    -   9 locations & teams

-   My statistical model:

    -   Mixed effects model:
        -   score \~ priming + (priming \| location)

::: notes
The Albarracin study investigated the effect of priming on SAT-like test scores. The protocol of the replication study was co-developed by the original authors and was administered to 884 participants across 9 locations and investigations. Distributing participants across different sites allowed for the estimation of effect heterogeneity.

To allow for effect heterogeneity across the different locations I implemented a mixed effect model. The dependent variable was score, predictor was the priming variable.
:::

## Aim

-   Implement Relevance measure to replication studies <!-- but really: write a good thesis -->

-   Create a reproducible and neat analysis pipeline

    -   Many similar analyses
    -   Avoid repetition

-   Build foundation for future research

::: notes
My goal was to implement the Relevance measure to replication studies.

In reality, my goal was to write a good thesis -- which I did write in R.

As many analysis processes are repeated often, and I wanted to avoid duplicate code. This was especially crucial for me during the development where small adjustments would have meant to change code in many places.

It was also important to me to make the code easily reusable, also by others.
:::

## Approach {auto-animate="true"}

```{r}
#| code-line-numbers: "2"
#| echo: true

#remotes::install_github("StefanThoma/ReplicationRelevance")
library(ReplicationRelevance)
```

-   R Package facilitates

    -   documentation
    -   writing generalized code

-   Can include Data

-   Complete & reproducible data analysis package

::: notes
The (maybe) obvious solution was to write an R package that can be hosted on GitHub.

Writing an R package allowed me to adopt certain R-package standards. This includes writing extensive (roxigen) documentation, thinking about code dependencies,
:::

## Approach {auto-animate="true"}

```{r}
#| code-line-numbers: "4,5"
#| echo: true
#| eval: false

#remotes::install_github("StefanThoma/ReplicationRelevance")
library(ReplicationRelevance)

# S4 study object
study <- setClass("study",
                  slots = list(
                    name = "character",
                    manyLabs = "character",
                    data.revised = "data.frame",
                    data.replication = "data.frame",
                    original = "list",
                    variables = "list",
                    var.of.interest = "character",
                    relevance.threshold = "numeric",
                    family = "character",
                    mixedModels = "list",
                    table = "data.frame",
                    difference.table = "list"
                  )
)
```

::: notes
My idea was to create one object for each study which will contain both the data and the results. This way, I could run the analysis script, export my study objects, and then import them to my thesis document. This would allow me to write the thesis parallel to developing the functionality in my package:

I could simply rerun the analysis script and subsequently rerun my thesis script, without any importing adjustments.
:::

## Approach {auto-animate="true"}

``` {.r code-line-numbers="1,2|4,5|10"}
alb5 <- new("study", 
            name = "alb5", 
            manyLabs = "ml5",
            data.revised = as.data.frame(alb5_rev), 
            data.replication = as.data.frame(alb5_rep),
            original = list(m.1 = 12.83, sd.1 = 1.86, n.1 = 18, 
                            m.2 = 10.78, sd.2 = 3.15, n.2 = 18), 
            variables = list("dv" = "SATTotal", 
                             "iv" = "Condition", 
                             "measure" = "SMD"),
            var.of.interest = "Condition",
            relevance.threshold = .1,
            family = "gaussian"
```

## Approach {auto-animate="true"}

``` {.r code-line-numbers="16,17|19,20|22,23"}
alb5 <- new("study", 
            name = "alb5", 
            manyLabs = "ml5",
            data.revised = as.data.frame(alb5_rev), 
            data.replication = as.data.frame(alb5_rep),
            original = list(m.1 = 12.83, sd.1 = 1.86, n.1 = 18, 
                            m.2 = 10.78, sd.2 = 3.15, n.2 = 18), 
            variables = list("dv" = "SATTotal", 
                             "iv" = "Condition", 
                             "measure" = "SMD"),
            var.of.interest = "Condition",
            relevance.threshold = .1,
            family = "gaussian"
            
# Fit mixed model
alb5@mixedModels <- MixedModels.study(alb5)

# Check model diagnostics
diagnosticPlot.study(alb5)

# Create outcome table
alb5@table <- relevance_table.study(alb5)
```

## Results

``` {.r code-line-numbers="24"}
alb5 <- new("study", 
            name = "alb5", 
            manyLabs = "ml5",
            data.revised = as.data.frame(alb5_rev), 
            data.replication = as.data.frame(alb5_rep),
            original = list(m.1 = 12.83, sd.1 = 1.86, n.1 = 18, 
                            m.2 = 10.78, sd.2 = 3.15, n.2 = 18), 
            variables = list("dv" = "SATTotal", 
                             "iv" = "Condition", 
                             "measure" = "SMD"),
            var.of.interest = "Condition",
            relevance.threshold = .1,
            family = "gaussian"
            
# Fit mixed model
alb5@mixedModels <- MixedModels.study(alb5)

# Check model diagnostics
diagnosticPlot.study(alb5)

# Create outcome table
alb5@table <- relevance_table.study(alb5)

plot_estimates.study(alb5)
```

## Results

![Relevance results](images/alb_both_plot.png)

::: notes
As we can see here, the original study showed a high value of its estimated relevance of 7.75. However, this came with a large confidence band. Still, the effect appeared to be relevant.

Overall, in a traditional setting, the replication would be considered successful because the fixed effect of priming was significant. In my opinion the picture is much less clear. Just one of the nine locations showed a significant effect while none could replicate the relevance of the original study. Further,

-- What is a successful replication??
:::

## My Learning Journey

-   Modularize code more

-   Separate Data from Results

-   Don't reinvent the wheel (use existing code-base)

-   Reduce unnecessary dependencies

-   Use CICD & tests

::: notes
--- Interface

--- Backend - Modularize more - Reduce code repetition even more - More careful about dependencies

--- Developer Setup: - Implement tests - Implement CICD - Scrum?

Avoid unstable packages, especially for core functionality.

Don't let the core functionality depend on unstable/very new packages
:::

# References

::: {#refs}
:::

# Excluded slides

## Both results

![Relevance results](images/alb.png)
